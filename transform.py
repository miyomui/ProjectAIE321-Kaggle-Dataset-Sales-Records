import pandas as pd
from sqlalchemy import create_engine, text
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

def transform_data():
    try:
        logging.info("üîÑ Starting Transformation Process...")

        # 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Database
        db_conn = 'postgresql://postgres:mysecretpassword@localhost:5432/sales_db'
        engine = create_engine(db_conn)

        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Schema 'production'
        with engine.connect() as conn:
            conn.execute(text("CREATE SCHEMA IF NOT EXISTS production;"))
            conn.commit()

        # 3. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
        df = pd.read_sql("SELECT * FROM raw_sales", engine)
        if df.empty:
            logging.warning("‚ö†Ô∏è No data in raw_sales!")
            return False

        # --- Data Cleansing ---
        logging.info("üßπ Cleaning data...")
        df = df.drop_duplicates() # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')
        df['Ship_Date'] = pd.to_datetime(df['Ship_Date'], errors='coerce')
        df = df.dropna(subset=['Order_Date', 'Ship_Date']) # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏á
        df = df[df['Ship_Date'] >= df['Order_Date']] # ‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏±‡πà‡∏á

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        numeric_cols = ['Units_Sold', 'Unit_Price', 'Total_Revenue', 'Total_Profit']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.dropna(subset=numeric_cols) # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏û‡∏±‡∏á

        # ---------------------------------------------------------
        # FEATURE ENGINEERING (‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏° KPI)
        # ---------------------------------------------------------
        logging.info("üõ†Ô∏è Creating new features based on KPIs...")

        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á 'Order_Year' (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö KPI: ‡∏î‡∏π‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏õ‡∏µ 2010-2017)
        df['Order_Year'] = df['Order_Date'].dt.year

        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á 'Days_to_Ship' (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö KPI: ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏±‡∏î‡∏™‡πà‡∏á)
        df['Days_to_Ship'] = (df['Ship_Date'] - df['Order_Date']).dt.days

        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á 'Delivery_Speed' (‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á)
        # ‡πÄ‡∏ä‡πà‡∏ô: ‡∏™‡πà‡∏á‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 3 ‡∏ß‡∏±‡∏ô = Fast, 3-7 ‡∏ß‡∏±‡∏ô = Normal, ‡πÄ‡∏Å‡∏¥‡∏ô 7 ‡∏ß‡∏±‡∏ô = Slow
        def categorize_speed(days):
            if days <= 3: return 'Fast'
            elif days <= 7: return 'Normal'
            else: return 'Slow'
        
        df['Delivery_Speed'] = df['Days_to_Ship'].apply(categorize_speed)

        # ---------------------------------------------------------
        # üìä KPI INSIGHTS (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏ä‡∏ß‡πå‡πÉ‡∏ô Terminal ‡πÄ‡∏•‡∏¢)
        # ---------------------------------------------------------
        logging.info("\n" + "="*50)
        logging.info("üìä PRELIMINARY KPI INSIGHTS")
        logging.info("="*50)

        # KPI 1: ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?
        top_item = df.groupby('Item_Type')['Total_Revenue'].sum().idxmax()
        top_item_val = df.groupby('Item_Type')['Total_Revenue'].sum().max()
        logging.info(f"üèÜ Top Item Type: {top_item} (Total Revenue: {top_item_val:,.2f})")

        # KPI 2: ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÉ‡∏î‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?
        top_country = df.groupby('Country')['Total_Revenue'].sum().idxmax()
        logging.info(f"üåç Top Country (Sales): {top_country}")

        # KPI 3: ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Ç‡∏≤‡∏¢‡πÉ‡∏î‡∏ó‡∏≥‡∏Å‡∏≥‡πÑ‡∏£‡∏£‡∏ß‡∏°‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î?
        top_channel = df.groupby('Sales_Channel')['Total_Profit'].sum().idxmax()
        logging.info(f"üí∞ Top Sales Channel (Profit): {top_channel}")

        # KPI 4: ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÉ‡∏î‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ '‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢' ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?
        top_avg_country = df.groupby('Country')['Total_Revenue'].mean().idxmax()
        logging.info(f"üìà Top Country (Avg Sales): {top_avg_country}")

        # KPI 5: Correlation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡∏ß‡∏±‡∏ô‡∏™‡πà‡∏á‡∏Ç‡∏≠‡∏á ‡∏Å‡∏±‡∏ö ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
        correlation = df['Days_to_Ship'].corr(df['Total_Revenue'])
        logging.info(f"üîó Correlation (Days vs Revenue): {correlation:.4f} (‡πÉ‡∏Å‡∏•‡πâ 0 ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)")
        
        logging.info("="*50 + "\n")

        # ---------------------------------------------------------
        
        # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Database
        logging.info("üíæ Saving to 'production.sales_data'...")
        df.to_sql('sales_data', engine, schema='production', if_exists='replace', index=False, chunksize=5000)

        logging.info("‚úÖ Transformation Complete!")
        return True

    except Exception as e:
        logging.error(f"‚ùå Error in Transformation: {e}")
        return False

if __name__ == "__main__":
    transform_data()